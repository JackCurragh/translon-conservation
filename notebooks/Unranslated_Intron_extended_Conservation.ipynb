{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conservation Analysis of Genomic Features\n",
    "\n",
    "This notebook analyzes conservation patterns in alternative transcript regions using PhyloCSF and PhyloP scores. The analysis pipeline is designed to handle multiple types of genomic features:\n",
    "- N-terminal extensions (ctes)\n",
    "- C-terminal extensions (CTEs)\n",
    "- Intronic regions\n",
    "\n",
    "## Setup\n",
    "First, we'll import required libraries and set up our basic configuration. We use:\n",
    "- `polars` for efficient data manipulation\n",
    "- `pyranges` for genomic icterval operations\n",
    "- `pyBigWig` for accessing conservation scores\n",
    "- `numpy` for numerical operations\n",
    "- `matplotlib` and `seaborn` for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from typing import List, Optional, Dict, Tuple\n",
    "from datetime import datetime\n",
    "\n",
    "# Add project root to Python path for imports\n",
    "project_root = str(Path().absolute().parent)\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Custom utilities\n",
    "from src.utils import ConservationTracker, ConservationAnalyzer, BEDHandler\n",
    "\n",
    "# Data handling\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import pyranges as pr\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_theme()\n",
    "sns.set_context(\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set up paths and parameters for the analysis. This notebook is configured for N-terminal extensions (ctes), but the same structure can be used for CTEs and intronic regions by modifying these parameters.\n",
    "\n",
    "Key parameters:\n",
    "- Feature type (NTE/CTE/intronic)\n",
    "- Input paths for feature data, annotations, and conservation scores\n",
    "- Analysis parameters like window size\n",
    "- Output directory structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature type\n",
    "FEATURE_TYPE = \"Untranslated_INTRONIC_EXTENDED\"  # One of: \"NTE\", \"CTE\", \"INTRONIC\"\n",
    "\n",
    "# Set up directory structure\n",
    "BASE_DIR = Path(\"..\")\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "RESULTS_DIR = BASE_DIR / \"results\" / FEATURE_TYPE.lower()\n",
    "BEDs = RESULTS_DIR / \"bed\"\n",
    "FIGs = RESULTS_DIR / \"figures\"\n",
    "TABLES = RESULTS_DIR / \"tables\"\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "BEDs.mkdir(parents=True, exist_ok=True)\n",
    "FIGs.mkdir(parents=True, exist_ok=True)\n",
    "TABLES.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Input paths\n",
    "feature_path = DATA_DIR / \"raw\" / \"intron_not_predicted.bed12\"\n",
    "gencode_path = DATA_DIR / \"raw\" / \"gencode.v47.annotation.gtf\"\n",
    "phylocsf_dir = DATA_DIR / \"raw\" / \"phylocsf\"\n",
    "phylop_path = DATA_DIR / \"raw\" / \"phyloP\" / \"PhyloP_470way.bw\"\n",
    "\n",
    "# Analysis parameters\n",
    "WINDOW_SIZE = 30  # Size of sliding window for conservation analysis\n",
    "MIN_REGION_SIZE = 10  # Minimum size of region to analyze\n",
    "SCORE_THRESHOLD = 0  # Threshold for calling positive conservation\n",
    "\n",
    "# Initialize our utility classes\n",
    "conservation_tracker = ConservationTracker(phylocsf_dir, phylop_path)\n",
    "conservation_analyzer = ConservationAnalyzer(window_size=WINDOW_SIZE)\n",
    "bed_handler = BEDHandler()\n",
    "\n",
    "# Verify paths exist\n",
    "for path in [feature_path, gencode_path, phylocsf_dir, phylop_path]:\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Required file/directory not found: {path}\")\n",
    "\n",
    "print(\"Configuration complete. Analysis will use:\")\n",
    "print(f\"- Feature type: {FEATURE_TYPE}\")\n",
    "print(f\"- Feature data: {feature_path}\")\n",
    "print(f\"- Results directory: {RESULTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing\n",
    "\n",
    "Load our N-terminal extension data from the BED12 file and prepare it for analysis. Steps include:\n",
    "1. Load the BED12 file using our custom handler\n",
    "2. Extract transcript IDs from feature names\n",
    "3. Basic QC checks on the loaded data\n",
    "4. Display summary statistics of our features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load feature data using our BED handler\n",
    "print(\"Loading feature data...\")\n",
    "feature_df = bed_handler.load_bed12(feature_path)\n",
    "\n",
    "# Extract transcript IDs from names and add region length\n",
    "feature_df = feature_df.with_columns([\n",
    "    # Extract transcript ID from feature name (assumes format: ENST00000123456_...)\n",
    "    pl.col(\"name\").str.split(\"_\").list.first().alias(\"transcript_id\"),\n",
    "    \n",
    "    # Calculate region length\n",
    "    (pl.col(\"chromEnd\") - pl.col(\"chromStart\")).alias(\"region_length\")\n",
    "])\n",
    "\n",
    "# Print basic statistics\n",
    "print(\"\\nFeature Statistics:\")\n",
    "print(f\"Total features loaded: {len(feature_df)}\")\n",
    "print(\"\\nChromosome distribution:\")\n",
    "print(feature_df.group_by(\"chrom\").agg(pl.count()).sort(\"chrom\"))\n",
    "print(\"\\nStrand distribution:\")\n",
    "print(feature_df.group_by(\"strand\").agg(pl.count()))\n",
    "print(\"\\nLength statistics:\")\n",
    "print(feature_df.select(\"region_length\").describe())\n",
    "\n",
    "# Quick length distribution plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(data=feature_df.to_pandas(), x=\"region_length\", bins=50)\n",
    "plt.title(\"Distribution of Feature Lengths\")\n",
    "plt.xlabel(\"Length (bp)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nData loading and preprocessing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extension Region Identification\n",
    "\n",
    "Before calculating conservation scores, we need to precisely identify the extension regions by:\n",
    "1. Loading CDS annotations from GENCODE\n",
    "2. Identifying the correct CDS start/end positions\n",
    "3. Determining the extension coordinates based on strand orientation:\n",
    "   - For + strand: region between chromStart and CDS start\n",
    "   - For - strand: region between CDS end and chromEnd\n",
    "4. Validating extension regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GENCODE annotation\n",
    "print(\"Loading GENCODE v47 annotation...\")\n",
    "gr = pr.read_gtf(gencode_path)\n",
    "\n",
    "# Get both CDS and exon annotations\n",
    "cds_annotation = gr[gr.Feature == \"CDS\"]\n",
    "exon_annotation = gr[gr.Feature == \"exon\"]\n",
    "\n",
    "print(f\"Found {len(cds_annotation)} CDS entries in GENCODE v47\")\n",
    "print(f\"Found {len(exon_annotation)} exon entries in GENCODE v47\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_cds_introns(cds_blocks_df):\n",
    "    \"\"\"\n",
    "    Identify introns between CDS blocks while properly handling strand orientation.\n",
    "\n",
    "    Args:\n",
    "        cds_blocks_df: DataFrame containing CDS blocks from PyRanges GTF\n",
    "                      Contains columns: Start, End, Strand, transcript_id\n",
    "\n",
    "    Returns:\n",
    "        DataFrame containing intron coordinates\n",
    "    \"\"\"\n",
    "    introns = []\n",
    "\n",
    "    # Group CDS blocks by transcript_id\n",
    "    for transcript_id, group in cds_blocks_df.groupby('transcript_id'):\n",
    "        # Sort CDS blocks based on genomic coordinates\n",
    "        # For - strand, we'll reverse the order later if needed\n",
    "        blocks = group.sort_values('Start').to_dict('records')\n",
    "\n",
    "        if len(blocks) <= 1:\n",
    "            continue\n",
    "\n",
    "        # Get strand information\n",
    "        strand = blocks[0]['Strand']\n",
    "\n",
    "        # For minus strand, reverse the order of blocks\n",
    "        if strand == '-':\n",
    "            blocks = blocks[::-1]\n",
    "\n",
    "        # Iterate through adjacent CDS blocks\n",
    "        for i in range(len(blocks) - 1):\n",
    "            current_cds = blocks[i]\n",
    "            next_cds = blocks[i + 1]\n",
    "\n",
    "            # Define intron boundaries based on strand\n",
    "            if strand == '+':\n",
    "                intron_start = current_cds['End']\n",
    "                intron_end = next_cds['Start']\n",
    "            else:\n",
    "                intron_start = next_cds['End']\n",
    "                intron_end = current_cds['Start']\n",
    "\n",
    "            # Validate intron coordinates\n",
    "            if intron_start >= intron_end:\n",
    "                continue\n",
    "\n",
    "            introns.append({\n",
    "                'transcript_id': transcript_id,\n",
    "                'strand': strand,\n",
    "                'intron_start': intron_start,\n",
    "                'intron_end': intron_end,\n",
    "                'chromosome': current_cds['Chromosome'],  # PyRanges uses 'Chromosome'\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(introns)\n",
    "\n",
    "# Get CDS annotations and ensure transcript_id is available\n",
    "cds_annotation = gr[gr.Feature == \"CDS\"]\n",
    "cds_df = cds_annotation.as_df()\n",
    "\n",
    "# Extract transcript_id from attributes if needed\n",
    "if 'transcript_id' not in cds_df.columns:\n",
    "    print(\"Extracting transcript_id from attributes...\")\n",
    "    # GTF format stores transcript_id in attributes column\n",
    "    cds_df['transcript_id'] = cds_df['gene_name'].str.extract('transcript_id \"([^\"]+)\"')\n",
    "\n",
    "print(f\"Found {len(cds_annotation)} CDS entries in GENCODE v47\")\n",
    "print(\"Identifying introns between CDS blocks...\")\n",
    "cds_introns = identify_cds_introns(cds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_all_scores(feature_df, cds_introns_pl, conservation_tracker, conservation_analyzer):\n",
    "    \"\"\"\n",
    "    Calculate conservation metrics for both translated regions and full CDS introns\n",
    "    \"\"\"\n",
    "    from time import time\n",
    "    import numpy as np\n",
    "    \n",
    "    # Initialize lists for all our metrics\n",
    "    metrics_lists = {\n",
    "        # Translated region metrics\n",
    "        'translated_frame_score': [],    # Score in translated region\n",
    "        'translated_max_score': [],      # Best frame in translated region\n",
    "        'translated_phylop': [],         # PhyloP in translated region\n",
    "        'translated_window_max': [],     # Best 30bp window in translated region\n",
    "        \n",
    "        # Untranslated intron metrics\n",
    "        'untranslated_frame_score': [],  # Score in untranslated regions\n",
    "        'untranslated_max_score': [],    # Best frame in untranslated regions\n",
    "        'untranslated_phylop': [],       # PhyloP in untranslated regions\n",
    "        'untranslated_window_max': [],   # Best 30bp window in untranslated regions\n",
    "        \n",
    "        # Region lengths\n",
    "        'translated_length': [],         # Length of translated region\n",
    "        'untranslated_length': [],      # Length of untranslated regions\n",
    "        'intron_start': [],             # Full intron start\n",
    "        'intron_end': [],               # Full intron end\n",
    "        'frame': []                      # Frame of translation\n",
    "    }\n",
    "    \n",
    "    total_features = len(feature_df)\n",
    "    processed = 0\n",
    "    matches_found = 0\n",
    "    \n",
    "    for row in feature_df.iter_rows(named=True):\n",
    "        if processed % 100 == 0:\n",
    "            print(f\"Processed {processed}/{total_features} features \"\n",
    "                  f\"({processed/total_features*100:.1f}%)\")\n",
    "        \n",
    "        processed += 1\n",
    "        \n",
    "        # Initialize default values\n",
    "        current_metrics = {key: None for key in metrics_lists.keys()}\n",
    "        \n",
    "        # Find matching introns\n",
    "        matching_introns = cds_introns_pl.filter(\n",
    "            (pl.col(\"chromosome\") == f\"chr{row['chrom']}\") &\n",
    "            (pl.col(\"intron_start\") <= row['thickStart']) &\n",
    "            (pl.col(\"intron_end\") >= row['thickEnd']) &\n",
    "            (pl.col(\"strand\") == row['strand'])\n",
    "        )\n",
    "        \n",
    "        if processed <= 2:  # Debug first 5 entries\n",
    "            print(f\"\\nProcessing entry {processed}:\")\n",
    "            print(f\"Looking for introns in transcript matching:\")\n",
    "            print(f\"Chrom: chr{row['chrom']}\")\n",
    "            print(f\"Region: {row['thickStart']}-{row['thickEnd']}\")\n",
    "            print(f\"Strand: {row['strand']}\")\n",
    "            print(f\"Found {len(matching_introns)} matching introns:\")\n",
    "            print(matching_introns)\n",
    "        \n",
    "        if len(matching_introns) == 0:\n",
    "            # Add None values for this row\n",
    "            for key in metrics_lists:\n",
    "                metrics_lists[key].append(None)\n",
    "            continue\n",
    "        \n",
    "        matches_found += 1\n",
    "        # Convert first matching intron to dict for easier access\n",
    "        intron_dict = matching_introns.row(0, named=True)\n",
    "        \n",
    "        current_metrics['intron_start'] = intron_dict['intron_start']\n",
    "        current_metrics['intron_end'] = intron_dict['intron_end']\n",
    "        \n",
    "        # Calculate frame\n",
    "        frame = (row['thickStart'] - intron_dict['intron_start']) % 3 + 1\n",
    "        current_metrics['frame'] = frame\n",
    "        \n",
    "        # 1. Analyze translated region\n",
    "        translated_scores, translated_phylop = conservation_tracker.get_conservation_scores(\n",
    "            row['chrom'],\n",
    "            row['thickStart'],\n",
    "            row['thickEnd'],\n",
    "            row['strand']\n",
    "        )\n",
    "        \n",
    "        current_metrics['translated_length'] = row['thickEnd'] - row['thickStart']\n",
    "        \n",
    "        if translated_scores:\n",
    "            frame_means = {\n",
    "                f: np.nanmean(scores) if len(scores) > 0 else np.nan \n",
    "                for f, scores in translated_scores.items()\n",
    "            }\n",
    "            \n",
    "            current_metrics['translated_frame_score'] = frame_means.get(frame)\n",
    "            current_metrics['translated_max_score'] = max(frame_means.values())\n",
    "            \n",
    "            scores = translated_scores[frame]\n",
    "            if len(scores) >= 30:\n",
    "                windows = [\n",
    "                    np.nanmean(scores[i:i+30])\n",
    "                    for i in range(len(scores) - 30 + 1)\n",
    "                ]\n",
    "                current_metrics['translated_window_max'] = float(max(windows))\n",
    "        \n",
    "        if translated_phylop is not None:\n",
    "            current_metrics['translated_phylop'] = float(np.nanmean(translated_phylop))\n",
    "        \n",
    "        # 2. Analyze untranslated regions\n",
    "        untranslated_regions = []\n",
    "        if row['thickStart'] > intron_dict['intron_start']:\n",
    "            untranslated_regions.append((\n",
    "                intron_dict['intron_start'],\n",
    "                row['thickStart']\n",
    "            ))\n",
    "        if row['thickEnd'] < intron_dict['intron_end']:\n",
    "            untranslated_regions.append((\n",
    "                row['thickEnd'],\n",
    "                intron_dict['intron_end']\n",
    "            ))\n",
    "        \n",
    "        # Combine scores from all untranslated regions\n",
    "        all_untranslated_scores = {1: [], 2: [], 3: []}\n",
    "        all_untranslated_phylop = []\n",
    "        total_untranslated_length = 0\n",
    "        \n",
    "        for start, end in untranslated_regions:\n",
    "            scores, phylop = conservation_tracker.get_conservation_scores(\n",
    "                row['chrom'],\n",
    "                start,\n",
    "                end,\n",
    "                row['strand']\n",
    "            )\n",
    "            \n",
    "            total_untranslated_length += end - start\n",
    "            \n",
    "            if scores:\n",
    "                for frame_num in [1, 2, 3]:\n",
    "                    all_untranslated_scores[frame_num].extend(scores.get(frame_num, []))\n",
    "            \n",
    "            if phylop is not None:\n",
    "                all_untranslated_phylop.extend(phylop)\n",
    "        \n",
    "        current_metrics['untranslated_length'] = total_untranslated_length\n",
    "        \n",
    "        if any(all_untranslated_scores.values()):\n",
    "            frame_means = {\n",
    "                f: np.nanmean(scores) if len(scores) > 0 else np.nan \n",
    "                for f, scores in all_untranslated_scores.items()\n",
    "            }\n",
    "            \n",
    "            current_metrics['untranslated_frame_score'] = frame_means.get(frame)\n",
    "            current_metrics['untranslated_max_score'] = max(frame_means.values())\n",
    "            \n",
    "            scores = all_untranslated_scores[frame]\n",
    "            if len(scores) >= 30:\n",
    "                windows = [\n",
    "                    np.nanmean(scores[i:i+30])\n",
    "                    for i in range(len(scores) - 30 + 1)\n",
    "                ]\n",
    "                current_metrics['untranslated_window_max'] = float(max(windows))\n",
    "        \n",
    "        if all_untranslated_phylop:\n",
    "            current_metrics['untranslated_phylop'] = float(np.nanmean(all_untranslated_phylop))\n",
    "        \n",
    "        # Add all metrics to their respective lists\n",
    "        for key in metrics_lists:\n",
    "            metrics_lists[key].append(current_metrics[key])\n",
    "    \n",
    "    print(f\"\\nProcessing Summary:\")\n",
    "    print(f\"Total entries processed: {total_features}\")\n",
    "    print(f\"Matching introns found: {matches_found}\")\n",
    "    print(f\"Percentage with matches: {(matches_found/total_features)*100:.1f}%\")\n",
    "    \n",
    "    # Add all metrics to DataFrame\n",
    "    return feature_df.with_columns([\n",
    "        pl.Series(name, values) for name, values in metrics_lists.items()\n",
    "    ])\n",
    "\n",
    "cds_introns_pl = pl.from_pandas(cds_introns)\n",
    "\n",
    "\n",
    "print(\"Calculating conservation scores...\")\n",
    "scored_df = calculate_all_scores(feature_df, cds_introns_pl, conservation_tracker, conservation_analyzer)\n",
    "\n",
    "# Add coordinate strings for reference\n",
    "scored_df = scored_df.with_columns([\n",
    "    # Translated region coordinates\n",
    "    (pl.col(\"chrom\") + \":\" + \n",
    "     pl.col(\"thickStart\").cast(pl.Utf8) + \"-\" +\n",
    "     pl.col(\"thickEnd\").cast(pl.Utf8)\n",
    "    ).alias(\"translated_coords\"),\n",
    "    \n",
    "    # Full intron coordinates\n",
    "    (pl.col(\"chrom\") + \":\" + \n",
    "     pl.col(\"intron_start\").cast(pl.Utf8) + \"-\" +\n",
    "     pl.col(\"intron_end\").cast(pl.Utf8)\n",
    "    ).alias(\"intron_coords\")\n",
    "])\n",
    "\n",
    "print(\"\\nSample of scored regions:\")\n",
    "print(scored_df.select([\n",
    "    \"transcript_id\",\n",
    "    \"translated_coords\",\n",
    "    \"intron_coords\",\n",
    "    \"strand\",\n",
    "    \"translated_frame_score\",\n",
    "    \"untranslated_frame_score\",\n",
    "    \"translated_phylop\",\n",
    "    \"untranslated_phylop\",\n",
    "    \"translated_length\",\n",
    "    \"untranslated_length\",\n",
    "    \"frame\"\n",
    "]).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conservation Score Calculation\n",
    "\n",
    "Calculate both PhyloCSF and PhyloP conservation scores for extension regions using our utility classes. For each region we:\n",
    "1. Use `ConservationTracker` to access scores\n",
    "2. Calculate metrics using `ConservationAnalyzer`\n",
    "3. Store results in a properly structured DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-Confidence Extension Analysis\n",
    "\n",
    "Filter and categorize the extensions based on conservation scores:\n",
    "1. Filter for positive PhyloCSF scores (indicating coding potential)\n",
    "2. Sort by conservation strength\n",
    "3. Separate novel vs. overlapping extensions\n",
    "4. Generate visualizations and summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show distribution of scores for both regions\n",
    "print(\"\\nScore statistics for intron regions:\")\n",
    "print(scored_df.select([\n",
    "   \"transcript_id\",\n",
    "   \"translated_coords\",\n",
    "   \"intron_coords\", \n",
    "   \"strand\",\n",
    "   \"translated_frame_score\",\n",
    "   \"untranslated_frame_score\",\n",
    "   \"translated_phylop\",\n",
    "   \"untranslated_phylop\",\n",
    "   \"frame\"\n",
    "]).head(10))\n",
    "\n",
    "# Create visualization comparing translated and untranslated regions\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 15))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# PhyloCSF scores distribution - translated vs untranslated\n",
    "data = scored_df.to_pandas()\n",
    "\n",
    "# Plot 1: PhyloCSF scores\n",
    "sns.histplot(\n",
    "    data=data['translated_frame_score'].dropna(),\n",
    "    bins=50,\n",
    "    ax=axes[0],\n",
    "    color='blue',\n",
    "    alpha=0.5,\n",
    "    label='Candidate'\n",
    ")\n",
    "sns.histplot(\n",
    "    data=data['untranslated_frame_score'].dropna(),\n",
    "    bins=50,\n",
    "    ax=axes[0],\n",
    "    color='red',\n",
    "    alpha=0.5,\n",
    "    label='Untranslated'\n",
    ")\n",
    "axes[0].set_title(\"Distribution of Frame-Matched PhyloCSF Scores\")\n",
    "axes[0].set_xlabel(\"PhyloCSF Score\")\n",
    "axes[0].legend()\n",
    "\n",
    "# Plot 2: PhyloP scores\n",
    "sns.histplot(\n",
    "    data=data['translated_phylop'].dropna(),\n",
    "    bins=50,\n",
    "    ax=axes[1],\n",
    "    color='blue',\n",
    "    alpha=0.5,\n",
    "    label='Candidate'\n",
    ")\n",
    "sns.histplot(\n",
    "    data=data['untranslated_phylop'].dropna(),\n",
    "    bins=50,\n",
    "    ax=axes[1],\n",
    "    color='red',\n",
    "    alpha=0.5,\n",
    "    label='Untranslated'\n",
    ")\n",
    "axes[1].set_title(\"Distribution of PhyloP Scores\")\n",
    "axes[1].set_xlabel(\"PhyloP Score\")\n",
    "axes[1].legend()\n",
    "\n",
    "# Plot 3: PhyloCSF comparison\n",
    "sns.scatterplot(\n",
    "    data=data.dropna(subset=['translated_frame_score', 'untranslated_frame_score']),\n",
    "    x='translated_frame_score',\n",
    "    y='untranslated_frame_score',\n",
    "    alpha=0.5,\n",
    "    ax=axes[2]\n",
    ")\n",
    "axes[2].set_title(\"Candidate vs Untranslated PhyloCSF Scores\")\n",
    "axes[2].set_xlabel(\"Candidate Region PhyloCSF\")\n",
    "axes[2].set_ylabel(\"Untranslated Region PhyloCSF\")\n",
    "axes[2].plot([0, 0], axes[2].get_ylim(), 'k--', alpha=0.3)  # vertical line at x=0\n",
    "axes[2].plot(axes[2].get_xlim(), [0, 0], 'k--', alpha=0.3)  # horizontal line at y=0\n",
    "\n",
    "# Plot 4: PhyloP comparison\n",
    "sns.scatterplot(\n",
    "    data=data.dropna(subset=['translated_phylop', 'untranslated_phylop']),\n",
    "    x='translated_phylop',\n",
    "    y='untranslated_phylop',\n",
    "    alpha=0.5,\n",
    "    ax=axes[3]\n",
    ")\n",
    "axes[3].set_title(\"Translated vs Untranslated PhyloP Scores\")\n",
    "axes[3].set_xlabel(\"Translated Region PhyloP\")\n",
    "axes[3].set_ylabel(\"Untranslated Region PhyloP\")\n",
    "\n",
    "# Plot 5: Region lengths\n",
    "sns.histplot(\n",
    "    data=data['translated_length'].dropna(),\n",
    "    bins=50,\n",
    "    ax=axes[4],\n",
    "    color='blue',\n",
    "    alpha=0.5,\n",
    "    label='Candidate'\n",
    ")\n",
    "sns.histplot(\n",
    "    data=data['untranslated_length'].dropna(),\n",
    "    bins=50,\n",
    "    ax=axes[4],\n",
    "    color='red',\n",
    "    alpha=0.5,\n",
    "    label='Untranslated'\n",
    ")\n",
    "axes[4].set_title(\"Distribution of Region Lengths\")\n",
    "axes[4].set_xlabel(\"Length (bp)\")\n",
    "axes[4].legend()\n",
    "\n",
    "# Plot 6: Window max scores\n",
    "sns.scatterplot(\n",
    "    data=data.dropna(subset=['translated_window_max', 'untranslated_window_max']),\n",
    "    x='translated_window_max',\n",
    "    y='untranslated_window_max',\n",
    "    alpha=0.5,\n",
    "    ax=axes[5]\n",
    ")\n",
    "axes[5].set_title(\"Best 30bp Window Comparison\")\n",
    "axes[5].set_xlabel(\"Candidate Region Best Window\")\n",
    "axes[5].set_ylabel(\"Untranslated Region Best Window\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Modified BED file writer for our specific columns\n",
    "def write_scored_bed(df, translated_col, untranslated_col, output_path, scale_factor=1000):\n",
    "    \"\"\"Write BED file with both translated and untranslated regions\"\"\"\n",
    "    \n",
    "    # Create entries for translated regions\n",
    "    translated_df = (df\n",
    "        .with_columns([\n",
    "            pl.format(\"chr{}\", pl.col(\"chrom\")).alias(\"chr_name\"),\n",
    "            pl.col(\"thickStart\").alias(\"start\"),\n",
    "            pl.col(\"thickEnd\").alias(\"end\"),\n",
    "            # Ensure unique names for browser display\n",
    "            pl.format(\"{}_translated\", pl.col(\"name\")).alias(\"feature_name\"),\n",
    "            # Scale scores to BED format (0-1000)\n",
    "            pl.when(pl.col(translated_col).is_null() | pl.col(translated_col).is_nan())\n",
    "            .then(0)\n",
    "            .otherwise(\n",
    "                ((pl.col(translated_col) - pl.col(translated_col).filter(~pl.col(translated_col).is_nan()).min()) / \n",
    "                 (pl.col(translated_col).filter(~pl.col(translated_col).is_nan()).max() - \n",
    "                  pl.col(translated_col).filter(~pl.col(translated_col).is_nan()).min()) * scale_factor)\n",
    "            )\n",
    "            .floor()\n",
    "            .cast(pl.Int64)\n",
    "            .clip(0, 1000)\n",
    "            .alias(\"bed_score\")\n",
    "        ])\n",
    "        .select([\n",
    "            \"chr_name\",\n",
    "            \"start\",\n",
    "            \"end\",\n",
    "            \"feature_name\",\n",
    "            \"bed_score\",\n",
    "            \"strand\"\n",
    "        ]))\n",
    "    \n",
    "    # Create entries for untranslated regions\n",
    "    untranslated_df = (df\n",
    "        .filter(pl.col(\"untranslated_length\") > 0)  # Only include regions with untranslated sequence\n",
    "        .with_columns([\n",
    "            pl.format(\"chr{}\", pl.col(\"chrom\")).alias(\"chr_name\"),\n",
    "            pl.format(\"{}_untranslated\", pl.col(\"name\")).alias(\"feature_name\"),\n",
    "            # Scale scores for untranslated regions\n",
    "            pl.when(pl.col(untranslated_col).is_null() | pl.col(untranslated_col).is_nan())\n",
    "            .then(0)\n",
    "            .otherwise(\n",
    "                ((pl.col(untranslated_col) - pl.col(untranslated_col).filter(~pl.col(untranslated_col).is_nan()).min()) / \n",
    "                 (pl.col(untranslated_col).filter(~pl.col(untranslated_col).is_nan()).max() - \n",
    "                  pl.col(untranslated_col).filter(~pl.col(untranslated_col).is_nan()).min()) * scale_factor)\n",
    "            )\n",
    "            .floor()\n",
    "            .cast(pl.Int64)\n",
    "            .clip(0, 1000)\n",
    "            .alias(\"bed_score\")\n",
    "        ]))\n",
    "    \n",
    "    # Get coordinates for untranslated regions\n",
    "    untranslated_df = untranslated_df.with_columns([\n",
    "        pl.col(\"intron_start\").alias(\"start\"),\n",
    "        pl.col(\"intron_end\").alias(\"end\")\n",
    "    ]).select([\n",
    "        \"chr_name\",\n",
    "        \"start\",\n",
    "        \"end\",\n",
    "        \"feature_name\",\n",
    "        \"bed_score\",\n",
    "        \"strand\"\n",
    "    ])\n",
    "    \n",
    "    # Combine and write\n",
    "    combined_df = pl.concat([translated_df, untranslated_df])\n",
    "    \n",
    "    combined_df.write_csv(\n",
    "        output_path,\n",
    "        separator=\"\\t\",\n",
    "        include_header=False\n",
    "    )\n",
    "    \n",
    "    print(f\"Wrote {len(combined_df)} entries to {output_path}\")\n",
    "    print(\"\\nFirst few lines of BED file:\")\n",
    "    print(combined_df.head())\n",
    "\n",
    "# Generate BED files for different score types\n",
    "date_str = datetime.now().strftime(\"%Y%m%d\")\n",
    "for score_type, (translated_col, untranslated_col) in {\n",
    "    \"phylocsf\": (\"translated_frame_score\", \"untranslated_frame_score\"),\n",
    "    \"phylop\": (\"translated_phylop\", \"untranslated_phylop\"),\n",
    "    \"window\": (\"translated_window_max\", \"untranslated_window_max\")\n",
    "}.items():\n",
    "    output_path = RESULTS_DIR / \"bed\" / f\"intron_{score_type}_{date_str}.bed\"\n",
    "    print(f\"\\nWriting {score_type} BED file...\")\n",
    "    print(output_path)\n",
    "    write_scored_bed(scored_df, translated_col, untranslated_col, output_path)\n",
    "\n",
    "# Print score statistics\n",
    "print(\"\\nScore column statistics:\")\n",
    "for col_pair in [\n",
    "    (\"translated_frame_score\", \"untranslated_frame_score\"),\n",
    "    (\"translated_phylop\", \"untranslated_phylop\"),\n",
    "    (\"translated_window_max\", \"untranslated_window_max\")\n",
    "]:\n",
    "    for col in col_pair:\n",
    "        if col in scored_df.columns:\n",
    "            print(f\"\\n{col}:\")\n",
    "            print(f\"Total values: {len(scored_df)}\")\n",
    "            print(f\"Null values: {scored_df.filter(pl.col(col).is_null()).height}\")\n",
    "            print(f\"NaN values: {scored_df.filter(pl.col(col).is_nan()).height}\")\n",
    "            print(f\"Negative values: {scored_df.filter(pl.col(col) < 0).height}\")\n",
    "            print(\"Overall statistics:\")\n",
    "            print(scored_df.select(pl.col(col)).describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Novel Extension Regions\n",
    "\n",
    "After calculating conservation scores for all potential N-terminal extensions, we need to identify which ones are truly novel (i.e., don't overlap with known coding sequences in other transcripts). This requires:\n",
    "\n",
    "1. Prerequisites:\n",
    "  - Bedtools installed (`conda install -c bioconda bedtools`)\n",
    "  - Our scored BED files from the conservation analysis\n",
    "  - GENCODE v47 CDS annotations in BED format\n",
    "\n",
    "2. Steps to identify novel extensions:\n",
    "\n",
    "```bash\n",
    "# First convert GENCODE GTF CDS regions to BED\n",
    "# If using UCSC genome browser coordinates (our case):\n",
    "awk '$3==\"CDS\" {print $1\"\\t\"$4-1\"\\t\"$5}' data/raw/gencode.v47.annotation.gtf > gencode.v47.cds.bed\n",
    "\n",
    "\n",
    "# Use bedtools ictersect to find non-overlapping regions - Examples\n",
    "# For matched frame scores:\n",
    "bedtools intersect -v -a cte_matched_frame_20241031.bed -b gencode.v47.cds.bed > novel_cte_matched_frame_20241031.bed\n",
    "\n",
    "# For PhyloP scores:\n",
    "bedtools intersect -v -a cte_phylop_20241031.bed -b gencode.v47.cds.bed > novel_cte_phylop_20241031.bed\n",
    "\n",
    "# For window max scores:\n",
    "bedtools intersect -v -a cte_window_max_20241031.bed -b gencode.v47.cds.bed > novel_cte_window_max_20241031.bed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Output Organization\n",
    "\n",
    "We should save both figures and data files for reproducibility and future reference. Here's what we should output:\n",
    "\n",
    "### Figures\n",
    "1. **Distribution Plots** (`results/cte/figures/`)\n",
    "  - Score distributions:\n",
    "    ```python\n",
    "    # Distribution plots (4-panel)\n",
    "    fig.savefig(RESULTS_DIR / \"figures\" / f\"cte_score_distributions_{date_str}.pdf\")\n",
    "    fig.savefig(RESULTS_DIR / \"figures\" / f\"cte_score_distributions_{date_str}.png\", dpi=300)\n",
    "    ```\n",
    "\n",
    "2. **Correlation Plots**\n",
    "  - PhyloCSF vs PhyloP\n",
    "  - Score vs length relationships\n",
    "  - Separate plots for clarity\n",
    "\n",
    "### Tables/Data Files \n",
    "1. **Summary Statistics** (`results/cte/tables/`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_df = scored_df.rename({col: col.replace('translated_', 'candidate_') for col in scored_df.columns if col.startswith('translated_')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory structure\n",
    "# RESULTS_DIR = Path(\"../results/retained_introns\")\n",
    "for subdir in [\"figures\", \"tables\", \"bed\"]:\n",
    "    (RESULTS_DIR / subdir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Get current date for file naming\n",
    "date_str = datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "# Save figures\n",
    "plt.figure(figsize=(15, 10))\n",
    "# Distribution plots (4-panel)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# PhyloCSF scores distribution\n",
    "sns.histplot(\n",
    "    data=scored_df.to_pandas(), \n",
    "    x=\"candidate_frame_score\",\n",
    "    bins=50,\n",
    "    ax=axes[0],\n",
    "    color='blue',\n",
    "    label='Candidate'\n",
    ")\n",
    "sns.histplot(\n",
    "    data=scored_df.to_pandas(), \n",
    "    x=\"untranslated_frame_score\",\n",
    "    bins=50,\n",
    "    ax=axes[0],\n",
    "    color='red',\n",
    "    alpha=0.5,\n",
    "    label='Untranslated'\n",
    ")\n",
    "axes[0].set_title(\"Distribution of Frame-Matched PhyloCSF Scores\")\n",
    "axes[0].set_xlabel(\"PhyloCSF Score\")\n",
    "axes[0].legend()\n",
    "\n",
    "# PhyloP score distribution\n",
    "sns.histplot(\n",
    "    data=scored_df.to_pandas(), \n",
    "    x=\"candidate_phylop\",\n",
    "    bins=50,\n",
    "    ax=axes[1],\n",
    "    color='blue',\n",
    "    label='Translated'\n",
    ")\n",
    "sns.histplot(\n",
    "    data=scored_df.to_pandas(), \n",
    "    x=\"untranslated_phylop\",\n",
    "    bins=50,\n",
    "    ax=axes[1],\n",
    "    color='red',\n",
    "    alpha=0.5,\n",
    "    label='Untranslated'\n",
    ")\n",
    "axes[1].set_title(\"Distribution of PhyloP Scores\")\n",
    "axes[1].set_xlabel(\"PhyloP Score\")\n",
    "axes[1].legend()\n",
    "\n",
    "# PhyloCSF comparison\n",
    "sns.scatterplot(\n",
    "    data=scored_df.to_pandas(),\n",
    "    x=\"candidate_frame_score\",\n",
    "    y=\"untranslated_frame_score\",\n",
    "    alpha=0.5,\n",
    "    ax=axes[2]\n",
    ")\n",
    "axes[2].set_title(\"PhyloCSF Score Comparison\")\n",
    "axes[2].set_xlabel(\"Translated Region Score\")\n",
    "axes[2].set_ylabel(\"Untranslated Region Score\")\n",
    "axes[2].plot([0, 0], axes[2].get_ylim(), 'k--', alpha=0.3)\n",
    "axes[2].plot(axes[2].get_xlim(), [0, 0], 'k--', alpha=0.3)\n",
    "\n",
    "# Region lengths\n",
    "sns.histplot(\n",
    "    data=scored_df.to_pandas(),\n",
    "    x=\"candidate_length\",\n",
    "    bins=50,\n",
    "    ax=axes[3],\n",
    "    color='blue',\n",
    "    label='Translated'\n",
    ")\n",
    "sns.histplot(\n",
    "    data=scored_df.to_pandas(),\n",
    "    x=\"untranslated_length\",\n",
    "    bins=50,\n",
    "    ax=axes[3],\n",
    "    color='red',\n",
    "    alpha=0.5,\n",
    "    label='Untranslated'\n",
    ")\n",
    "axes[3].set_title(\"Distribution of Region Lengths\")\n",
    "axes[3].set_xlabel(\"Length (bp)\")\n",
    "axes[3].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "fig.savefig(RESULTS_DIR / \"figures\" / f\"untranslated_intron_score_distributions_{date_str}.pdf\")\n",
    "fig.savefig(RESULTS_DIR / \"figures\" / f\"untranslated_intron_score_distributions_{date_str}.png\", dpi=300)\n",
    "\n",
    "# Save summary statistics\n",
    "metrics = [\n",
    "    \"candidate_frame_score\",\n",
    "    \"untranslated_frame_score\",\n",
    "    \"candidate_phylop\",\n",
    "    \"untranslated_phylop\",\n",
    "    \"candidate_window_max\",\n",
    "    \"untranslated_window_max\",\n",
    "    \"candidate_length\",\n",
    "    \"untranslated_length\"\n",
    "]\n",
    "\n",
    "summary_stats = scored_df.select(metrics).describe()\n",
    "summary_stats.write_csv(RESULTS_DIR / \"tables\" / f\"untranslated_intron_summary_stats_{date_str}.tsv\", separator=\"\\t\")\n",
    "\n",
    "# Save full results\n",
    "scored_df.write_csv(RESULTS_DIR / \"tables\" / f\"untranslated_intron_full_results_{date_str}.tsv\", separator=\"\\t\")\n",
    "\n",
    "# Save high-confidence results\n",
    "high_conf = scored_df.filter(\n",
    "    (pl.col(\"candidate_frame_score\") > 10) &\n",
    "    (pl.col(\"candidate_phylop\") > 2) &\n",
    "    (pl.col(\"candidate_frame_score\") > pl.col(\"untranslated_frame_score\") * 2)\n",
    ")\n",
    "high_conf.write_csv(RESULTS_DIR / \"tables\" / f\"untranslated_intron_high_confidence_{date_str}.tsv\", separator=\"\\t\")\n",
    "\n",
    "# Save BED files\n",
    "for score_type, (translated_col, untranslated_col) in {\n",
    "    \"phylocsf\": (\"candidate_frame_score\", \"untranslated_frame_score\"),\n",
    "    \"phylop\": (\"candidate_phylop\", \"untranslated_phylop\"),\n",
    "    \"window\": (\"candidate_window_max\", \"untranslated_window_max\")\n",
    "}.items():\n",
    "    output_path = RESULTS_DIR / \"bed\" / f\"untranslated_intron_{score_type}_{date_str}.bed\"\n",
    "    write_scored_bed(scored_df, translated_col, untranslated_col, output_path)\n",
    "\n",
    "print(\"Results saved in:\")\n",
    "print(f\"- Figures: {RESULTS_DIR}/figures/\")\n",
    "print(f\"- Tables: {RESULTS_DIR}/tables/\")\n",
    "print(f\"- BED files: {RESULTS_DIR}/bed/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "translon-conservation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
